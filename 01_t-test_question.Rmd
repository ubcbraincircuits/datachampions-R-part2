---
title: "T-test_script"
output: html_document
date: '2022-06-20'
---

# One Sample T-test. 
```{r}
# First set the sample size we are going to use when we draw our sample. 
n = 

# Create a sample to use via the rnorm command. Call this variable "sample".
# Give it a mean of 10 and a standard deviation of 2.5
# Hint: use help(rnorm) to determine the inputs
sample = 
  
# plot it in a histogram using hist()


# Specify the x values for which the t-distribution will be calculated for plotting
x = seq(-5,5,by = 0.001)

# Try making the t-distribution yourself. Use help(dt) for more information. Hint: the number of degree of freedom is n-1. Use the x specified above.
tdistr = 
  
# what's our t value and where is it on the distribution?  What do you predict for the result of
# the test?
# Hint: The formula for t is (mean(y)-10)/(sd(y)/sqrt(length(y))). What variable name do we replace y with?
obs_t = 

# To visualize the t distribution and see where our observed value of the test statistic falls, we make a plot where the rejection region is highlighted in red and our test statistic is labelled by a vertical blue line.
plot(x,tdistr,type = "l",main = "t distribution",xlab = "t",ylab = "Probability Density") + polygon(c(x[x >= 1.73], max(x), 1.73), c(tdistr[x >= 1.73], 0, 0), col = "red")+ abline(v=obs_t, col="blue")

# R's t-test function is called t.test. run help(t.test) to get a feel for the function.

# do the t.test:
# remember, the mean of our null is 10 and we want to do a right, one-sided test (greater than).
# Hint: use help(t.test) to determine inputs


# There are a lot of outputs, but for our purposes we want to focus on 
# the p-value. 
```

# just for funsies:  How often do we make a type I error?  
It's easy to estimate for type I here.  We know mu.  Above. It's 10.

So what's a type I error again?  H0 rejected when it's true.
In our case H0 is true.
let's generate a sample and do the test lots of times to see how often
we reject H0.
```{r}
N_iter = 20000
h_out = 0
alpha = 0.05
for (i in 1:N_iter){
  x = rnorm(n, mean = 10, sd = 2.5)
  p=t.test(x,mu = 10,alternative = "g")[["p.value"]]
  if (p < alpha){
  h_out = h_out+1
  }
  }
# So what's the rate of type I error?

h_out/N_iter

# It should be close to our significance level!  If H0 is true and we
# reject the Null we are out in the tail of distribution by chance.  And
# alpha is the probability of that!
```
# Ok that's all for now.  Go back to slides.


# Two sample T-test.
```{r}
# Let's make sample sizes of x = 20 and y = 40. For x, use a mean of 10 and sd of 2.5. For y, use a mean of 11 and a sd of 2.5.
# Hint: Use rnorm as we did for the 1-sample t-test above
x = 
y = 
  
# Look at them using hist().

  
```

```{r}
# Here I made the variances equal. In practice if we are using a two
# sample t test and allowing ourselves to assume equal variances then we
# compute what is called the pooled standard deviation. 

# Calculate the pooled standard deviation by using the following formula
# sp = sqrt(((length(a)-1)*sd(a)^2+(length(b)-1)*sd(b)^2)/(length(a)+length(b)-2))
# Hint: what should you replace a and b with?
sp = 

# Then we need to think about our H0 for a moment.

# Let's say our H0 is that the population means are equal.ie mean(x)=mean(y).
# So we can calculate our t statistic:
# Hint: the formula for t is (mean(a)-mean(b))/sqrt((sp^2)/length(a)+(sp^2)/length(b))
  
obs_t = 

# Now we need to think about our Ha.  Let's say we thought it might be the
# case that mean(x) < mean(y), That means our t stat would be out there in the left
# tail of the distribution.  Think about an extreme case where we would feel confident
# in saying mean(x) < mean(y).  Imagine mean(x) was 0 and
# mean(y) was 1000.  If the samples were large and xbar ~mean(x) and ybar ~mean(y) then
# tstat would be large and negative! This means to the left.

# Ok so what does our t distribution look like?  Where does our observed
# value of t land?  What does that imply for our testing?

# Use dt to calculate the t-distribution as done above in the 1-sample t-test. Use help(dt) if needed.
# Hint: the number of degrees of freedom will be length(x)+length(y)-2. Use the s specified below.
s = seq(-5,5,by=.1)
tdistr = 

crit = abs(qt(p = 0.05, df = length(x)+length(y)-2))
plot(s,tdistr,type = "l",main = "t distribution, 2 samp test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -crit), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")

# Ok now use the t.test to perform a two-sample t-test. We do not need to set mu, instead we need to 
# input both samples into t.test(). We also need to specify that the variances of our samples are 
# equal and that we want a "left" or "lesser" one-sided t-test. 

# Hint: use help(t.test) to determine inputs


# Do the results of the t-test confirm your suspicions?
```

# Paired T-test
```{r}
# Ok we need two samples again. Let's call them x and y again. 
# Set both sample sizes to 20. Set the mean of one of x to 10 and the mean of y to 11. 
# Standard deviation for both is 2.5. Use help(rnorm) if needed.
n = 
x =
y =

# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we 
# are going to calculate the diffs with our expectation being that there will be a negative difference if the null is false. 
  
the_diffs=

# What's our H0?  Let's say it is that the means are equal again.

# What's our t stat?
# Hint: t = mean(a)/(sd(a)/sqrt(length(a))). What is a?

obs_t = 

# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?

# Calculate the t dsitribution again using the s specified below. Use help(dt) if needed.
# Hint: the dof will be length(the_diffs) - 1
s = seq(-5,5,by=.1)
tdistr = 

crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(s, tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")

# What's our Ha?  Let's say that it is mean(x)<mean(y), so we need to look at a
# rejection region in the left tail of the distribution.
# Ok, do the test. It's t.test again but this time we are going to specify that they are paired. 

t.test(x,y,paired = TRUE, alternative = "l")
```

 