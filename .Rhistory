# rejection region in the left tail of the distribution.
# Ok, do the test. It's t.test again but this time we are going to specify that they are paired.
t.test(x,y,paired = TRUE, alternative = "l")
# In order to make sure we are not breaking the assumptions of the t-test, I am going to quickly make a couple of samples for us.
sample_1 = rnorm(25, mean = 10, sd = 2.5)
sample_2 = rnorm(50, mean = 13, sd = 2.5)
t.test(sample_1, sample_2, var.equal = TRUE)
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
tdistr = dt(seq(-5,5,by=.01),length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(seq(-5,5,by=.01),tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
tdistr = dt(seq(-5,5,by=.001),length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(seq(-5,5,by=.001),tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
tdistr = dt(seq(-5,5,by=.1),length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(seq(-5,5,by=.1),tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# What's our Ha?  Let's say that it is mean(x)<mean(y), so we need to look at a
# rejection region in the left tail of the distribution.
# Ok, do the test. It's t.test again but this time we are going to specify that they are paired.
t.test(x,y,paired = TRUE, alternative = "l")
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
tdistr = dt(seq(-5,5,by=.001),length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(seq(-5,5,by=.001),tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
tdistr = dt(seq(-5,5,by=.001),length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(seq(-5,5,by=.001),tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
s=seq(-5,5,by=.001)
tdistr = dt(s,length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(s,tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# What's our Ha?  Let's say that it is mean(x)<mean(y), so we need to look at a
# rejection region in the left tail of the distribution.
# Ok, do the test. It's t.test again but this time we are going to specify that they are paired.
t.test(x,y,paired = TRUE, alternative = "l")
# Here I made the variances equal. In practice if we are using a two
# sample t test and allowing ourselves to assume equal variances then we
# compute what is called the pooled standard deviation.
sp = ((length(x)-1)*sd(x)^2+(length(y)-1)*sd(y)^2)/(length(x)+length(y)-2)
sp = sqrt(sp)
# Then we need to think about our H0 for a moment.
# Let's say our H0 is that the population means are equal.ie mean(x)=mean(y).
# So we can calculate our t statistic as follows:
obs_t = (mean(x)-mean(y))/sqrt((sp^2)/length(x)+(sp^2)/length(y))
# Now we need to think about our Ha.  Let's say we thought it might be the
# case that mean(x) < mean(y), That means our t stat would be out there in the left
# tail of the distribution.  Think about an extreme case where we would feel confident
# in saying mean(x) < mean(y).  Imagine mean(x) was 0 and
# mean(y) was 1000.  If the samples were large and xbar ~mean(x) and ybar ~mean(y) then
# tstat would be large and negative! This means to the left.
# Ok so what does our t distribution look like?  Where does our observed
# value of t land?  What does that imply for our testing?
tdistr = dt(seq(-5,5,by = .1),length(x)+length(y)-2)
s = seq(-5,5,by=.001)
crit = abs(qt(p = 0.05, df = length(x)+length(y)-2))
plot(s,tdistr,type = "l",main = "t distribution, 2 samp test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -crit), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# First set the sample size we are going to use when we draw our sample. Let's do a sample size of 20 and
# call the variable n
n = 20
# Create a sample to use via the rnorm command. Call this variable "sample".
# Give it a mean of 10 and a standard deviation of 2.5
# plot it in a histogram using hist()
sample = rnorm(n, mean = 10, sd = 2.5)
hist(sample)
# Quickly remake the t distribution, by copying the code we used last time.
x = seq(-5,5,by = 0.001)
tdistr = dt(x,n-1)
plot(x,tdistr,type = "l",main = "t distribution",xlab = "t",ylab = "Probability Density")
# what's our t value and where is it on the distribution?  What do you predict for the result of
# the test?
obs_t = (mean(sample)-10)/(sd(sample)/sqrt(length(sample)))
plot(x,tdistr,type = "l",main = "t distribution",xlab = "t",ylab = "Probability Density") + polygon(c(x[x >= 1.73], max(x), 1.73), c(tdistr[x >= 1.73], 0, 0), col = "red")+ abline(v=obs_t, col="blue")
# R's t-test function is called t.test. run help(t.test) to get a feel for the function.
# do the t.test:
# remember, the mean of our null is 10 and we want to do a right, one-sided test (greater than).
t.test(sample,mu = 10,alternative="g")
# There are a lot of outputs, but for our purposes we want to focus on
# the p-value.
#Let's do sample sizes of x = 20 and y = 40 (same sd).
x = rnorm(20, mean = 10, sd = 2.5)
y = rnorm(40, mean = 11, sd = 2.5)
# Look at them using hist().
hist(x)
hist(y)
# Here I made the variances equal. In practice if we are using a two
# sample t test and allowing ourselves to assume equal variances then we
# compute what is called the pooled standard deviation.
sp = ((length(x)-1)*sd(x)^2+(length(y)-1)*sd(y)^2)/(length(x)+length(y)-2)
sp = sqrt(sp)
# Then we need to think about our H0 for a moment.
# Let's say our H0 is that the population means are equal.ie mean(x)=mean(y).
# So we can calculate our t statistic as follows:
obs_t = (mean(x)-mean(y))/sqrt((sp^2)/length(x)+(sp^2)/length(y))
# Now we need to think about our Ha.  Let's say we thought it might be the
# case that mean(x) < mean(y), That means our t stat would be out there in the left
# tail of the distribution.  Think about an extreme case where we would feel confident
# in saying mean(x) < mean(y).  Imagine mean(x) was 0 and
# mean(y) was 1000.  If the samples were large and xbar ~mean(x) and ybar ~mean(y) then
# tstat would be large and negative! This means to the left.
# Ok so what does our t distribution look like?  Where does our observed
# value of t land?  What does that imply for our testing?
s = seq(-5,5,by=.001)
tdistr = dt(s,length(x)+length(y)-2)
crit = abs(qt(p = 0.05, df = length(x)+length(y)-2))
plot(s,tdistr,type = "l",main = "t distribution, 2 samp test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -crit), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok now use the t.test to perform a two-sample t-test. We do not need to set mu, instead we need to
# input both samples into t.test(). We also need to specify that the variances of our samples are
# equal and that we want a "left" or "lesser" one-sided t-test.
t.test(x,y,var.equal=TRUE, alternative = "l")
# Do the results of the t-test confirm your suspicions?
N_iter = 20000
h_out = 0
alpha = 0.05
for (i in 1:N_iter){
x = rnorm(n, mean = 10, sd = 2.5)
p=t.test(x,mu = 10,alternative = "g")[["p.value"]]
if (p < alpha){
h_out = h_out+1
}
}
# So what's the rate of type I error?
h_out/N_iter
# It should be close to our significance level!  If H0 is true and we
# reject the Null we are out in the tail of distribution by chance.  And
# alpha is the probability of that!
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
s=seq(-5,5,by=.001)
tdistr = dt(s,length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(s,tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# What's our Ha?  Let's say that it is mean(x)<mean(y), so we need to look at a
# rejection region in the left tail of the distribution.
# Ok, do the test. It's t.test again but this time we are going to specify that they are paired.
t.test(x,y,paired = TRUE, alternative = "l")
# In order to make sure we are not breaking the assumptions of the t-test, I am going to quickly make a couple of samples for us.
sample_1 = rnorm(25, mean = 10, sd = 2.5)
sample_2 = rnorm(50, mean = 13, sd = 2.5)
t.test(sample_1, sample_2, var.equal = TRUE)
A <- c(117.1, 121.3, 127.8, 121.9, 117.4, 124.5, 119.5, 115.1)
B <- c(123.5, 125.3, 126.5, 127.9, 122.1, 125.6, 129.8, 117.2)
dat <- data.frame(weight = c(A,B),
company = rep(c("A","B"), each=8))
dat$company <- factor(dat$company)
boxplot(weight ~ company, data = dat)
# Use help(wilcox.test) to determine the inputs for this function. You can use ~ to specify the relationship between weight and company.
wt =
A <- c(117.1, 121.3, 127.8, 121.9, 117.4, 124.5, 119.5, 115.1)
B <- c(123.5, 125.3, 126.5, 127.9, 122.1, 125.6, 129.8, 117.2)
dat <- data.frame(weight = c(A,B),
company = rep(c("A","B"), each=8))
dat$company <- factor(dat$company)
boxplot(weight ~ company, data = dat)
# Use help(wilcox.test) to determine the inputs for this function. You can use ~ to specify the relationship between weight and company.
wt = wilcox.test(weight ~ company, data = dat, exact = TRUE)
x <- -1: (8*8 + 1)
# The p-value is calculated by determining the index for which the cumulative sum of fx exceeds 0.05. Therefore, we should be careful to index correctly on x as well.
fx <- dwilcox(x, length(A), length(B)) # dwilcox is a builtin R function that determines the Wilcoxon distribution given the sizes of the two samples
thresholdValue <- 0.025 # two-sided test since we want 0.025 as both ends
ix <- which(cumsum(fx) <= thresholdValue) # cumulative sum is summing probabilities up to the edge of the rejection region (e.g. thresholdValue) in order to determine the rejection region. However, the edge of the rejection region might not be exactly at a significance level of 0.05 as the value of alpha will likely fall between the discrete values of the W distribution.
tx <- x[length(ix)] # determines the maximum x-value for which the sum of probabilities is still under the threshold value
# Plot the distribution, rejection region, and observed test statistic
plot(x, fx, type = "h", col = "violet",
main =  "Probabilities (density) of Wilcoxon-Statist.(n=8, m=8)") + abline(v=wt$statistic, col="blue")+ polygon(c(x[x <= tx], tx, tx), c(fx[x <= tx], 0, 0), col=rgb(1, 0, 0,0.5), border=NA)
# Combine the data from group A and B
pooled <- c(A,B)
# Try resampling the combined data from above. What are we trying to calculate here? Use help(sample) to get started.
mean(sample(pooled, length(A), FALSE))-mean(sample(pooled, length(B), FALSE))
# Divide the combined data into two groups and calculate their difference in means 2000 times
nresamples <- 2000
dist <- replicate(nresamples, mean(sample(pooled, length(A), FALSE))-mean(sample(pooled, length(B), FALSE)))
# Plot the histogram
histogram = hist(dist, xlim = c(-6, 6), col = "black", breaks = 100)
thresholdValue <- 0.025
ix <- which(cumsum(histogram$counts)/nresamples <= thresholdValue)
tx <- histogram$breaks[length(ix)]
tx
abline(v = mean(A)-mean(B), col = "blue", lwd = 2)
polygon(x=c(-6,-6,tx,tx), y=c(0,60,60,0), col="#FF990022", border=F)
# Divide the combined data into two groups and calculate their difference in means 2000 times
nresamples <- 2000
dist <- replicate(nresamples, mean(sample(pooled, length(A), FALSE))-mean(sample(pooled, length(B), FALSE)))
# Plot the histogram
histogram = hist(dist, xlim = c(-6, 6), col = "black", breaks = 100)
thresholdValue <- 0.025
ix <- which(cumsum(histogram$counts)/nresamples <= thresholdValue)
tx <- histogram$breaks[length(ix)]
# tx
abline(v = mean(A)-mean(B), col = "blue", lwd = 2)
polygon(x=c(-6,-6,tx,tx), y=c(0,60,60,0), col="#FF990022", border=F)
# Divide the combined data into two groups and calculate their difference in means 2000 times
nresamples <- 2000
dist <- replicate(nresamples, mean(sample(pooled, length(A), FALSE))-mean(sample(pooled, length(B), FALSE)))
# Plot the histogram
histogram = hist(dist, xlim = c(-6, 6), col = "black", breaks = 100)
thresholdValue <- 0.025
ix <- which(cumsum(histogram$counts)/nresamples <= thresholdValue)
tx <- histogram$breaks[length(ix)]
tx
abline(v = mean(A)-mean(B), col = "blue", lwd = 2)
polygon(x=c(-6,-6,tx,tx), y=c(0,60,60,0), col="#FF990022", border=F)
tx
abline(v = mean(A)-mean(B), col = "blue", lwd = 2)
# Divide the combined data into two groups and calculate their difference in means 2000 times
nresamples <- 2000
dist <- replicate(nresamples, mean(sample(pooled, length(A), FALSE))-mean(sample(pooled, length(B), FALSE)))
# Plot the histogram
histogram = hist(dist, xlim = c(-6, 6), col = "black", breaks = 100)
thresholdValue <- 0.025
ix <- which(cumsum(histogram$counts)/nresamples <= thresholdValue)
tx <- histogram$breaks[length(ix)]
abline(v = mean(A)-mean(B), col = "blue", lwd = 2)
polygon(x=c(-6,-6,tx,tx), y=c(0,60,60,0), col="#FF990022", border=F)
# Divide the combined data into two groups and calculate their difference in means 2000 times
nresamples <- 2000
dist <- replicate(nresamples, mean(sample(pooled, length(A), FALSE))-mean(sample(pooled, length(B), FALSE)))
# Plot the histogram
histogram = hist(dist, xlim = c(-6, 6), col = "black", breaks = 100)
thresholdValue <- 0.025
ix <- which(cumsum(histogram$counts)/nresamples <= thresholdValue)
tx <- histogram$breaks[length(ix)]
abline(v = mean(A)-mean(B), col = "blue", lwd = 2)
polygon(x=c(-6,-6,tx,tx), y=c(0,60,60,0), col="#FF990022", border=F)
samplesizes <- seq(from=10,to=200,by=10)
# TODO: Use the power.t.test() function to compute the power of a sequence of sample sizes. Assume that the magnitude of difference is 0.3 unites and the standard deviation is 0.28 units. Then, use the plot() function to plot that relationship.
power_samplesizes <- power.t.test(n=samplesizes,delta=0.3,sd=0.28)$power
plot(samplesizes,
power_samplesizes,
xlim=c(0,200),
xlab="Sample size",
ylab="Expected power",
ylim=c(0.5,1),
type="b",
col="darkorange",
lwd=5,axes=FALSE)
axis(1,at=c(0,50,100,150,200))
power.t.test(n=6,delta=0.3,sd=0.28,type="two.sample")
# TODO: Use the power.t.test() function to calculate the sample size needed to achieve a power of 90%, assuming that the magnitude of the difference is 0.3 units and the standard deviation is 0.28 units.
help("power.t.test")
samplesizes <- seq(from=10,to=200,by=10)
# TODO: Use the power.t.test() function to compute the power of a sequence of sample sizes. Assume that the magnitude of difference is 0.3 unites and the standard deviation is 0.28 units. Then, use the plot() function to plot that relationship.
# Run as whole block
differences <- seq(from=0.1,to=2,by=0.1)
samplesize_sd04 <- sapply(differences,
function(d){power.t.test(power=0.9,
delta=d,
sd=0.4,
type="two.sample")$n})
samplesize_sd03 <- sapply(differences,
function(d){power.t.test(power=0.9,
delta=d,
sd=0.3,
type="two.sample")$n})
plot(differences,
samplesize_sd04,
xlim=c(0,2),
xlab="Expected difference between groups",
ylab="Required sample size",
ylim=c(0,350),
type="b",
col="darkblue",
lwd=5,axes=FALSE)
lines(differences, samplesize_sd03,col="turquoise",lwd=5,type="b")
axis(1,at=c(0,0.2,0.5,1,1.5,2))
axis(2,at=c(350,100,50,10,0))
legend(x="topright",lwd=5,bty="n",legend=c("SD=0.4","SD=0.3"),col=c("darkblue","turquoise"))
power.t.test(n=6,delta=0.3,sd=0.28,type="two.sample")
# TODO: Use the power.t.test() function to calculate the sample size needed to achieve a power of 90%, assuming that the magnitude of the difference is 0.3 units and the standard deviation is 0.28 units.
help("power.t.test")
power.t.test(power=0.9,delta=0.3,sd=0.28,type="two.sample")
# Run as whole block
samplesizes <- seq(from=10,to=200,by=10)
# TODO: Use the power.t.test() function to compute the power of a sequence of sample sizes. Assume that the magnitude of difference is 0.3 unites and the standard deviation is 0.28 units. Then, use the plot() function to plot that relationship.
power_samplesizes <- power.t.test(n=samplesizes,delta=0.3,sd=0.28)$power
plot(samplesizes,
power_samplesizes,
xlim=c(0,200),
xlab="Sample size",
ylab="Expected power",
ylim=c(0.5,1),
type="b",
col="darkorange",
lwd=5,axes=FALSE)
axis(1,at=c(0,50,100,150,200))
axis(2,at=c(0.5,0.75,1),labels=paste(c(50,75,100),"%"))
# Run as whole block
differences <- seq(from=0.1,to=2,by=0.1)
samplesize_sd04 <- sapply(differences,
function(d){power.t.test(power=0.9,
delta=d,
sd=0.4,
type="two.sample")$n})
samplesize_sd03 <- sapply(differences,
function(d){power.t.test(power=0.9,
delta=d,
sd=0.3,
type="two.sample")$n})
plot(differences,
samplesize_sd04,
xlim=c(0,2),
xlab="Expected difference between groups",
ylab="Required sample size",
ylim=c(0,350),
type="b",
col="darkblue",
lwd=5,axes=FALSE)
lines(differences, samplesize_sd03,col="turquoise",lwd=5,type="b")
axis(1,at=c(0,0.2,0.5,1,1.5,2))
axis(2,at=c(350,100,50,10,0))
legend(x="topright",lwd=5,bty="n",legend=c("SD=0.4","SD=0.3"),col=c("darkblue","turquoise"))
# First set the sample size we are going to use when we draw our sample. Let's do a sample size of 20 and
# call the variable n
n = 20
# Create a sample to use via the rnorm command. Call this variable "sample".
# Give it a mean of 10 and a standard deviation of 2.5
# plot it in a histogram using hist()
sample = rnorm(n, mean = 10, sd = 2.5)
hist(sample)
# Quickly remake the t distribution, by copying the code we used last time.
x = seq(-5,5,by = 0.001)
tdistr = dt(x,n-1)
plot(x,tdistr,type = "l",main = "t distribution",xlab = "t",ylab = "Probability Density")
# what's our t value and where is it on the distribution?  What do you predict for the result of
# the test?
obs_t = (mean(sample)-10)/(sd(sample)/sqrt(length(sample)))
plot(x,tdistr,type = "l",main = "t distribution",xlab = "t",ylab = "Probability Density") + polygon(c(x[x >= 1.73], max(x), 1.73), c(tdistr[x >= 1.73], 0, 0), col = "red")+ abline(v=obs_t, col="blue")
# do the t.test:
# remember, the mean of our null is 10 and we want to do a right, one-sided test (greater than).
t.test(sample,mu = 10,alternative="g")
# There are a lot of outputs, but for our purposes we want to focus on
# the p-value.
# Two sample T-test.
```{r}
#Let's do sample sizes of x = 20 and y = 40 (same sd).
x = rnorm(20, mean = 10, sd = 2.5)
y = rnorm(40, mean = 11, sd = 2.5)
hist(x)
hist(y)
hist(x)
hist(y)
```{r}
sp = ((length(x)-1)*sd(x)^2+(length(y)-1)*sd(y)^2)/(length(x)+length(y)-2)
sp = sqrt(sp)
obs_t = (mean(x)-mean(y))/sqrt((sp^2)/length(x)+(sp^2)/length(y))
s = seq(-5,5,by=.001)
tdistr = dt(s,length(x)+length(y)-2)
crit = abs(qt(p = 0.05, df = length(x)+length(y)-2))
plot(s,tdistr,type = "l",main = "t distribution, 2 samp test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -crit), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok now use the t.test to perform a two-sample t-test. We do not need to set mu, instead we need to
# input both samples into t.test(). We also need to specify that the variances of our samples are
# equal and that we want a "left" or "lesser" one-sided t-test.
t.test(x,y,var.equal=TRUE, alternative = "l")
# Do the results of the t-test confirm your suspicions?
# just for funsies:  How often do we make a type I error?
It's easy to estimate for type I here.  We know mu.  Above. It's 10.
So what's a type I error again?  H0 rejected when it's true.
In our case H0 is true.
let's generate a sample and do the test lots of times to see how often
we reject H0.
```{r}
N_iter = 20000
h_out = 0
alpha = 0.05
for (i in 1:N_iter){
x = rnorm(n, mean = 10, sd = 2.5)
p=t.test(x,mu = 10,alternative = "g")[["p.value"]]
if (p < alpha){
h_out = h_out+1
}
}
# So what's the rate of type I error?
h_out/N_iter
# It should be close to our significance level!  If H0 is true and we
# reject the Null we are out in the tail of distribution by chance.  And
# alpha is the probability of that!
# It should be close to our significance level!  If H0 is true and we
# reject the Null we are out in the tail of distribution by chance.  And
# alpha is the probability of that!
# Paired T-test
```{r}
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
the_diffs=x-y
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
s=seq(-5,5,by=.001)
tdistr = dt(s,length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(s,tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
t.test(x,y,paired = TRUE, alternative = "l")
t.test(x,y,paired = TRUE, alternative = "l")
# Example question.
Perform a two sample t-test on our sample_1 and sample_2 vectors. Use the help() function to figure out how we can use the t.test function to do a two sample t-test. Please specify that the variances are equal for our 2 samples in this test.
```{r}
# In order to make sure we are not breaking the assumptions of the t-test, I am going to quickly make a couple of samples for us.
sample_1 = rnorm(25, mean = 10, sd = 2.5)
sample_2 = rnorm(50, mean = 13, sd = 2.5)
t.test(sample_1, sample_2, var.equal = TRUE)
# In order to make sure we are not breaking the assumptions of the t-test, I am going to quickly make a couple of samples for us.
sample_1 = rnorm(25, mean = 10, sd = 2.5)
sample_2 = rnorm(50, mean = 13, sd = 2.5)
t.test(sample_1, sample_2, var.equal = TRUE)
```{r}
# In order to make sure we are not breaking the assumptions of the t-test, I am going to quickly make a couple of samples for us.
sample_1 = rnorm(25, mean = 10, sd = 2.5)
```{r}
# In order to make sure we are not breaking the assumptions of the t-test, I am going to quickly make a couple of samples for us.
sample_1 = rnorm(25, mean = 10, sd = 2.5)
sample_2 = rnorm(50, mean = 13, sd = 2.5)
t.test(sample_1, sample_2, var.equal = TRUE)
# In order to make sure we are not breaking the assumptions of the t-test, I am going to quickly make a couple of samples for us.
sample_1 = rnorm(25, mean = 10, sd = 2.5)
sample_2 = rnorm(50, mean = 13, sd = 2.5)
t.test(sample_1, sample_2, var.equal = TRUE)
```{r}
