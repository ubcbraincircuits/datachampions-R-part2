library(here)
here()
setwd(here())
getwd()
setwd()
getwd()
unlink()
help(unlink)
unlink("here")
getwd()
install.packages("here")
library(here)
setwd(here())
getwd()
install.packages("ggpubr")
install.packages("tidyverse")
differences <- seq(from=0.1,to=2,by=0.1)
samplesize_sd04 <- sapply(differences,
function(d){power.t.test(power=0.9,
delta=d,
sd=0.4,
type="two.sample")$n})
samplesize_sd03 <- sapply(differences,
function(d){power.t.test(power=0.9,
delta=d,
sd=0.3,
type="two.sample")$n})
plot(differences,
samplesize.sd04,
xlim=c(0,2),
xlab="Expected difference between groups",
ylab="Required sample size",
ylim=c(0,350),
type="b",
col="darkblue",
lwd=5,axes=FALSE)
differences <- seq(from=0.1,to=2,by=0.1)
samplesize_sd04 <- sapply(differences,
function(d){power.t.test(power=0.9,
delta=d,
sd=0.4,
type="two.sample")$n})
samplesize_sd03 <- sapply(differences,
function(d){power.t.test(power=0.9,
delta=d,
sd=0.3,
type="two.sample")$n})
plot(differences,
samplesize_sd04,
xlim=c(0,2),
xlab="Expected difference between groups",
ylab="Required sample size",
ylim=c(0,350),
type="b",
col="darkblue",
lwd=5,axes=FALSE)
lines(differences, samplesize_sd03,col="turquoise",lwd=5,type="b")
axis(1,at=c(0,0.2,0.5,1,1.5,2))
axis(2,at=c(350,100,50,10,0))
legend(x="topright",lwd=5,bty="n",legend=c("SD=0.4","SD=0.3"),col=c("darkblue","turquoise"))
samplesizes <- seq(from=10,to=200,by=10)
power_samplesizes <- power.prop.test(n=samplesizes,p1=0.3,p2=0.55)$power
plot(samplesizes,
power.samplesizes,
xlim=c(0,200),
xlab="Sample size",
ylab="Expected power",
ylim=c(0,1),
type="b",
col="darkorange",
lwd=5,axes=FALSE)
plot(samplesizes,
power_samplesizes,
xlim=c(0,200),
xlab="Sample size",
ylab="Expected power",
ylim=c(0,1),
type="b",
col="darkorange",
lwd=5,axes=FALSE)
samplesizes <- seq(from=10,to=200,by=10)
power_samplesizes <- power.t.test(n=samplesizes,p1=0.3,sd-0.28)$power
samplesizes <- seq(from=10,to=200,by=10)
power_samplesizes <- power.t.test(n=samplesizes,delta=0.3,sd-0.28)$power
samplesizes <- seq(from=10,to=200,by=10)
power_samplesizes <- power.t.test(n=samplesizes,delta=0.3,sd=0.28)$power
plot(samplesizes,
power_samplesizes,
xlim=c(0,200),
xlab="Sample size",
ylab="Expected power",
ylim=c(0,1),
type="b",
col="darkorange",
lwd=5,axes=FALSE)
axis(1,at=c(0,50,100,150,200))
axis(2,at=c(0,0.25,0.5,0.75,1),labels=paste(c(0,25,50,75,100),"%"))
samplesizes <- seq(from=10,to=200,by=10)
power_samplesizes <- power.t.test(n=samplesizes,delta=0.3,sd=0.28)$power
plot(samplesizes,
power_samplesizes,
xlim=c(0,200),
xlab="Sample size",
ylab="Expected power",
ylim=c(0,1),
type="b",
col="darkorange",
lwd=5,axes=FALSE)
axis(1,at=c(0,50,100,150,200))
axis(2,at=c(0,0.25,0.5,0.75,1),labels=paste(c(50,75,100),"%"))
samplesizes <- seq(from=10,to=200,by=10)
power_samplesizes <- power.t.test(n=samplesizes,delta=0.3,sd=0.28)$power
plot(samplesizes,
power_samplesizes,
xlim=c(0,200),
xlab="Sample size",
ylab="Expected power",
ylim=c(0,1),
type="b",
col="darkorange",
lwd=5,axes=FALSE)
axis(1,at=c(0,50,100,150,200))
axis(2,at=c(0.5,0.75,1),labels=paste(c(50,75,100),"%"))
samplesizes <- seq(from=10,to=200,by=10)
power_samplesizes <- power.t.test(n=samplesizes,delta=0.3,sd=0.28)$power
plot(samplesizes,
power_samplesizes,
xlim=c(0,200),
xlab="Sample size",
ylab="Expected power",
ylim=c(0,1),
type="b",
col="darkorange",
lwd=5,axes=FALSE)
axis(1,at=c(0,50,100,150,200))
axis(2,at=c(0,0.25,0.5,0.75,1),labels=paste(c(0,25,50,75,100),"%"))
samplesizes <- seq(from=10,to=200,by=10)
power_samplesizes <- power.t.test(n=samplesizes,delta=0.3,sd=0.28)$power
plot(samplesizes,
power_samplesizes,
xlim=c(0,200),
xlab="Sample size",
ylab="Expected power",
ylim=c(0.5,1),
type="b",
col="darkorange",
lwd=5,axes=FALSE)
axis(1,at=c(0,50,100,150,200))
axis(2,at=c(0.5,0.75,1),labels=paste(c(50,75,100),"%"))
power.t.test(n=6,delta=0.3,sd=0.28,type="two.sample")
# TODO: Use the power.t.test() function to calculate the sample size needed to achieve a power of 90%, assuming that the magnitude of the difference is 0.3 units and the standard deviation is 0.28 units.
help("power.t.test")
power.t.test(power=0.9,delta=0.3,sd=0.28,type="two.sample")
samplesizes <- seq(from=10,to=200,by=10)
# TODO: Use the power.t.test() function to compute the power of a sequence of sample sizes. Assume that the magnitude of difference is 0.3 unites and the standard deviation is 0.28 units. Then, use the plot() function to plot that relationship.
power_samplesizes <- power.t.test(n=samplesizes,delta=0.3,sd=0.28)$power
plot(samplesizes,
power_samplesizes,
xlim=c(0,200),
xlab="Sample size",
ylab="Expected power",
ylim=c(0.5,1),
type="b",
col="darkorange",
lwd=5,axes=FALSE)
axis(1,at=c(0,50,100,150,200))
axis(2,at=c(0.5,0.75,1),labels=paste(c(50,75,100),"%"))
differences <- seq(from=0.1,to=2,by=0.1)
samplesize_sd04 <- sapply(differences,
function(d){power.t.test(power=0.9,
delta=d,
sd=0.4,
type="two.sample")$n})
samplesize_sd03 <- sapply(differences,
function(d){power.t.test(power=0.9,
delta=d,
sd=0.3,
type="two.sample")$n})
plot(differences,
samplesize_sd04,
xlim=c(0,2),
xlab="Expected difference between groups",
ylab="Required sample size",
ylim=c(0,350),
type="b",
col="darkblue",
lwd=5,axes=FALSE)
lines(differences, samplesize_sd03,col="turquoise",lwd=5,type="b")
axis(1,at=c(0,0.2,0.5,1,1.5,2))
axis(2,at=c(350,100,50,10,0))
legend(x="topright",lwd=5,bty="n",legend=c("SD=0.4","SD=0.3"),col=c("darkblue","turquoise"))
# First set the sample size we are going to use when we draw our sample. Let's do a sample size of 20 and
# call the variable n
n = 20
# Create a sample to use via the rnorm command. Call this variable "sample".
# Give it a mean of 10 and a standard deviation of 2.5
# plot it in a histogram using hist()
sample = rnorm(n, mean = 10, sd = 2.5)
hist(sample)
# Quickly remake the t distribution, by copying the code we used last time.
x = seq(-5,5,by = 0.001)
tdistr = dt(x,n-1)
plot(x,tdistr,type = "l",main = "t distribution",xlab = "t",ylab = "Probability Density")
# what's our t value and where is it on the distribution?  What do you predict for the result of
# the test?
obs_t = (mean(sample)-10)/(sd(sample)/sqrt(length(sample)))
plot(x,tdistr,type = "l",main = "t distribution",xlab = "t",ylab = "Probability Density") + polygon(c(x[x >= 1.73], max(x), 1.73), c(tdistr[x >= 1.73], 0, 0), col = "red")+ abline(v=obs_t, col="blue")
# R's t-test function is called t.test. run help(t.test) to get a feel for the function.
# do the t.test:
# remember, the mean of our null is 10 and we want to do a right, one-sided test (greater than).
t.test(sample,mu = 10,alternative="g")
# There are a lot of outputs, but for our purposes we want to focus on
# the p-value.
#Let's do sample sizes of x = 20 and y = 40 (same sd).
x = rnorm(20, mean = 10, sd = 2.5)
y = rnorm(40, mean = 11, sd = 2.5)
# Look at them using hist().
hist(x)
hist(y)
# Here I made the variances equal. In practice if we are using a two
# sample t test and allowing ourselves to assume equal variances then we
# compute what is called the pooled standard deviation.
sp = ((length(x)-1)*sd(x)^2+(length(y)-1)*sd(y)^2)/(length(x)+length(y)-2)
sp = sqrt(sp)
# Then we need to think about our H0 for a moment.
# Let's say our H0 is that the population means are equal.ie mean(x)=mean(y).
# So we can calculate our t statistic as follows:
obs_t = (mean(x)-mean(y))/sqrt((sp^2)/length(x)+(sp^2)/length(y))
# Now we need to think about our Ha.  Let's say we thought it might be the
# case that mean(x) < mean(y), That means our t stat would be out there in the left
# tail of the distribution.  Think about an extreme case where we would feel confident
# in saying mean(x) < mean(y).  Imagine mean(x) was 0 and
# mean(y) was 1000.  If the samples were large and xbar ~mean(x) and ybar ~mean(y) then
# tstat would be large and negative! This means to the left.
# Ok so what does our t distribution look like?  Where does our observed
# value of t land?  What does that imply for our testing?
tdistr = dt(seq(-5,5,by = .1),length(x)+length(y)-2)
s = seq(-5,5,by=.1)
crit = abs(qt(p = 0.05, df = length(x)+length(y)-2))
plot(s,tdistr,type = "l",main = "t distribution, 2 samp test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -crit), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok now use the t.test to perform a two-sample t-test. We do not need to set mu, instead we need to
# input both samples into t.test(). We also need to specify that the variances of our samples are
# equal and that we want a "left" or "lesser" one-sided t-test.
t.test(x,y,var.equal=TRUE, alternative = "l")
# Do the results of the t-test confirm your suspicions?
N_iter = 20000
h_out = 0
alpha = 0.05
for (i in 1:N_iter){
x = rnorm(n, mean = 10, sd = 2.5)
p=t.test(x,mu = 10,alternative = "g")[["p.value"]]
if (p < alpha){
h_out = h_out+1
}
}
# So what's the rate of type I error?
h_out/N_iter
# It should be close to our significance level!  If H0 is true and we
# reject the Null we are out in the tail of distribution by chance.  And
# alpha is the probability of that!
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
tdistr = dt(seq(-5,5,by=.1),length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(seq(-5,5,by=.1),tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# What's our Ha?  Let's say that it is mean(x)<mean(y), so we need to look at a
# rejection region in the left tail of the distribution.
# Ok, do the test. It's t.test again but this time we are going to specify that they are paired.
t.test(x,y,paired = TRUE, alternative = "l")
# In order to make sure we are not breaking the assumptions of the t-test, I am going to quickly make a couple of samples for us.
sample_1 = rnorm(25, mean = 10, sd = 2.5)
sample_2 = rnorm(50, mean = 13, sd = 2.5)
t.test(sample_1, sample_2, var.equal = TRUE)
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
tdistr = dt(seq(-5,5,by=.01),length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(seq(-5,5,by=.01),tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
tdistr = dt(seq(-5,5,by=.001),length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(seq(-5,5,by=.001),tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
tdistr = dt(seq(-5,5,by=.1),length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(seq(-5,5,by=.1),tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# What's our Ha?  Let's say that it is mean(x)<mean(y), so we need to look at a
# rejection region in the left tail of the distribution.
# Ok, do the test. It's t.test again but this time we are going to specify that they are paired.
t.test(x,y,paired = TRUE, alternative = "l")
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
tdistr = dt(seq(-5,5,by=.001),length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(seq(-5,5,by=.001),tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
tdistr = dt(seq(-5,5,by=.001),length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(seq(-5,5,by=.001),tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
s=seq(-5,5,by=.001)
tdistr = dt(s,length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(s,tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# What's our Ha?  Let's say that it is mean(x)<mean(y), so we need to look at a
# rejection region in the left tail of the distribution.
# Ok, do the test. It's t.test again but this time we are going to specify that they are paired.
t.test(x,y,paired = TRUE, alternative = "l")
# Here I made the variances equal. In practice if we are using a two
# sample t test and allowing ourselves to assume equal variances then we
# compute what is called the pooled standard deviation.
sp = ((length(x)-1)*sd(x)^2+(length(y)-1)*sd(y)^2)/(length(x)+length(y)-2)
sp = sqrt(sp)
# Then we need to think about our H0 for a moment.
# Let's say our H0 is that the population means are equal.ie mean(x)=mean(y).
# So we can calculate our t statistic as follows:
obs_t = (mean(x)-mean(y))/sqrt((sp^2)/length(x)+(sp^2)/length(y))
# Now we need to think about our Ha.  Let's say we thought it might be the
# case that mean(x) < mean(y), That means our t stat would be out there in the left
# tail of the distribution.  Think about an extreme case where we would feel confident
# in saying mean(x) < mean(y).  Imagine mean(x) was 0 and
# mean(y) was 1000.  If the samples were large and xbar ~mean(x) and ybar ~mean(y) then
# tstat would be large and negative! This means to the left.
# Ok so what does our t distribution look like?  Where does our observed
# value of t land?  What does that imply for our testing?
tdistr = dt(seq(-5,5,by = .1),length(x)+length(y)-2)
s = seq(-5,5,by=.001)
crit = abs(qt(p = 0.05, df = length(x)+length(y)-2))
plot(s,tdistr,type = "l",main = "t distribution, 2 samp test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -crit), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# First set the sample size we are going to use when we draw our sample. Let's do a sample size of 20 and
# call the variable n
n = 20
# Create a sample to use via the rnorm command. Call this variable "sample".
# Give it a mean of 10 and a standard deviation of 2.5
# plot it in a histogram using hist()
sample = rnorm(n, mean = 10, sd = 2.5)
hist(sample)
# Quickly remake the t distribution, by copying the code we used last time.
x = seq(-5,5,by = 0.001)
tdistr = dt(x,n-1)
plot(x,tdistr,type = "l",main = "t distribution",xlab = "t",ylab = "Probability Density")
# what's our t value and where is it on the distribution?  What do you predict for the result of
# the test?
obs_t = (mean(sample)-10)/(sd(sample)/sqrt(length(sample)))
plot(x,tdistr,type = "l",main = "t distribution",xlab = "t",ylab = "Probability Density") + polygon(c(x[x >= 1.73], max(x), 1.73), c(tdistr[x >= 1.73], 0, 0), col = "red")+ abline(v=obs_t, col="blue")
# R's t-test function is called t.test. run help(t.test) to get a feel for the function.
# do the t.test:
# remember, the mean of our null is 10 and we want to do a right, one-sided test (greater than).
t.test(sample,mu = 10,alternative="g")
# There are a lot of outputs, but for our purposes we want to focus on
# the p-value.
#Let's do sample sizes of x = 20 and y = 40 (same sd).
x = rnorm(20, mean = 10, sd = 2.5)
y = rnorm(40, mean = 11, sd = 2.5)
# Look at them using hist().
hist(x)
hist(y)
# Here I made the variances equal. In practice if we are using a two
# sample t test and allowing ourselves to assume equal variances then we
# compute what is called the pooled standard deviation.
sp = ((length(x)-1)*sd(x)^2+(length(y)-1)*sd(y)^2)/(length(x)+length(y)-2)
sp = sqrt(sp)
# Then we need to think about our H0 for a moment.
# Let's say our H0 is that the population means are equal.ie mean(x)=mean(y).
# So we can calculate our t statistic as follows:
obs_t = (mean(x)-mean(y))/sqrt((sp^2)/length(x)+(sp^2)/length(y))
# Now we need to think about our Ha.  Let's say we thought it might be the
# case that mean(x) < mean(y), That means our t stat would be out there in the left
# tail of the distribution.  Think about an extreme case where we would feel confident
# in saying mean(x) < mean(y).  Imagine mean(x) was 0 and
# mean(y) was 1000.  If the samples were large and xbar ~mean(x) and ybar ~mean(y) then
# tstat would be large and negative! This means to the left.
# Ok so what does our t distribution look like?  Where does our observed
# value of t land?  What does that imply for our testing?
s = seq(-5,5,by=.001)
tdistr = dt(s,length(x)+length(y)-2)
crit = abs(qt(p = 0.05, df = length(x)+length(y)-2))
plot(s,tdistr,type = "l",main = "t distribution, 2 samp test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -crit), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# Ok now use the t.test to perform a two-sample t-test. We do not need to set mu, instead we need to
# input both samples into t.test(). We also need to specify that the variances of our samples are
# equal and that we want a "left" or "lesser" one-sided t-test.
t.test(x,y,var.equal=TRUE, alternative = "l")
# Do the results of the t-test confirm your suspicions?
N_iter = 20000
h_out = 0
alpha = 0.05
for (i in 1:N_iter){
x = rnorm(n, mean = 10, sd = 2.5)
p=t.test(x,mu = 10,alternative = "g")[["p.value"]]
if (p < alpha){
h_out = h_out+1
}
}
# So what's the rate of type I error?
h_out/N_iter
# It should be close to our significance level!  If H0 is true and we
# reject the Null we are out in the tail of distribution by chance.  And
# alpha is the probability of that!
# Ok we need two samples again. Let's call them x and y again.
# Set both sample sizes to 200. Set the mean of one of x to 10 and the mean of y to 11.
# Standard deviation for both is 2.5
x = rnorm(n, mean = 10, sd = 2.5)
y = rnorm(n, mean = 11, sd = 2.5)
# Ok, so what are our diffs? does the order matter? In this case our HA is that mean(x)<mean(y), so we
# are going to calculate the diffs as x-y with our expectation being that there will be a negative
# difference if the null is false.
the_diffs=x-y
# What's our H0?  Let's say it is that the means are equal again.
# What's our t stat?
obs_t = mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))
# What does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?
s=seq(-5,5,by=.001)
tdistr = dt(s,length(the_diffs)-1)
crit = abs(qt(p = 0.05, df = length(the_diffs)-1))
plot(s,tdistr,type = "l",main = "t distribution, paired test example",xlab = "",ylab = "") + polygon(c(s[s <= -crit], -crit, -5), c(tdistr[s <= -crit], 0, 0), col = "red") + abline(v=obs_t, col="blue")
# What's our Ha?  Let's say that it is mean(x)<mean(y), so we need to look at a
# rejection region in the left tail of the distribution.
# Ok, do the test. It's t.test again but this time we are going to specify that they are paired.
t.test(x,y,paired = TRUE, alternative = "l")
# In order to make sure we are not breaking the assumptions of the t-test, I am going to quickly make a couple of samples for us.
sample_1 = rnorm(25, mean = 10, sd = 2.5)
sample_2 = rnorm(50, mean = 13, sd = 2.5)
t.test(sample_1, sample_2, var.equal = TRUE)
